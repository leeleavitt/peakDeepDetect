{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\r\n# ms-python.python added\r\nimport os\r\ntry:\r\n\tos.chdir(os.path.join(os.getcwd(), '..'))\r\n\tprint(os.getcwd())\r\nexcept:\r\n\tpass\r\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_2 (LSTM)                (None, 100)               40800     \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 101       \n=================================================================\nTotal params: 40,901\nTrainable params: 40,901\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/10\n200/200 [==============================] - 79s 394ms/step - loss: 0.5606 - acc: 0.7463 - val_loss: 0.4921 - val_acc: 0.8010\nEpoch 2/10\n200/200 [==============================] - 85s 427ms/step - loss: 0.5827 - acc: 0.6867 - val_loss: 0.6951 - val_acc: 0.5206\nEpoch 3/10\n200/200 [==============================] - 103s 515ms/step - loss: 0.6877 - acc: 0.5395 - val_loss: 0.6894 - val_acc: 0.5228\nEpoch 4/10\n200/200 [==============================] - 103s 516ms/step - loss: 0.5895 - acc: 0.6796 - val_loss: 0.6882 - val_acc: 0.5180\nEpoch 5/10\n200/200 [==============================] - 96s 478ms/step - loss: 0.6765 - acc: 0.5713 - val_loss: 0.6688 - val_acc: 0.6248\nEpoch 6/10\n200/200 [==============================] - 82s 412ms/step - loss: 0.6594 - acc: 0.5970 - val_loss: 0.6384 - val_acc: 0.7718\nEpoch 7/10\n200/200 [==============================] - 78s 391ms/step - loss: 0.6640 - acc: 0.6106 - val_loss: 0.6910 - val_acc: 0.5185\nEpoch 8/10\n200/200 [==============================] - 77s 384ms/step - loss: 0.6851 - acc: 0.5389 - val_loss: 0.6878 - val_acc: 0.5204\nEpoch 9/10\n200/200 [==============================] - 83s 414ms/step - loss: 0.6794 - acc: 0.5598 - val_loss: 0.6864 - val_acc: 0.5237\nEpoch 10/10\n200/200 [==============================] - 74s 370ms/step - loss: 0.6854 - acc: 0.5469 - val_loss: 0.6858 - val_acc: 0.5368\nTrain on 7412 samples, validate on 3651 samples\nEpoch 1/25\n7412/7412 [==============================] - 56s 8ms/sample - loss: 0.6813 - acc: 0.5725 - val_loss: 0.6925 - val_acc: 0.5199\nEpoch 2/25\n7412/7412 [==============================] - 56s 8ms/sample - loss: 0.6702 - acc: 0.6097 - val_loss: 0.8793 - val_acc: 0.4793\nEpoch 3/25\n7412/7412 [==============================] - 57s 8ms/sample - loss: 0.6864 - acc: 0.5712 - val_loss: 0.6910 - val_acc: 0.5199\nEpoch 4/25\n7412/7412 [==============================] - 60s 8ms/sample - loss: 0.6652 - acc: 0.6015 - val_loss: 0.6305 - val_acc: 0.7579\nEpoch 5/25\n7412/7412 [==============================] - 59s 8ms/sample - loss: 0.6604 - acc: 0.6123 - val_loss: 0.6763 - val_acc: 0.5930\nEpoch 6/25\n7412/7412 [==============================] - 58s 8ms/sample - loss: 0.6737 - acc: 0.5859 - val_loss: 0.6763 - val_acc: 0.5741\nEpoch 7/25\n7412/7412 [==============================] - 58s 8ms/sample - loss: 0.6696 - acc: 0.5977 - val_loss: 0.6977 - val_acc: 0.5190\nEpoch 8/25\n7412/7412 [==============================] - 59s 8ms/sample - loss: 0.6700 - acc: 0.5884 - val_loss: 0.6737 - val_acc: 0.5755\nEpoch 9/25\n7412/7412 [==============================] - 67s 9ms/sample - loss: 0.6506 - acc: 0.6172 - val_loss: 0.7001 - val_acc: 0.5563\nEpoch 10/25\n7412/7412 [==============================] - 57s 8ms/sample - loss: 0.5155 - acc: 0.7717 - val_loss: 0.4011 - val_acc: 0.8526\nEpoch 11/25\n7412/7412 [==============================] - 57s 8ms/sample - loss: 0.3391 - acc: 0.8768 - val_loss: 0.3104 - val_acc: 0.8685\nEpoch 12/25\n7412/7412 [==============================] - 60s 8ms/sample - loss: 0.2995 - acc: 0.8863 - val_loss: 0.2918 - val_acc: 0.8918\nEpoch 13/25\n7412/7412 [==============================] - 63s 8ms/sample - loss: 0.2685 - acc: 0.8972 - val_loss: 0.2768 - val_acc: 0.8976\nEpoch 14/25\n7412/7412 [==============================] - 64s 9ms/sample - loss: 0.2614 - acc: 0.9010 - val_loss: 0.2607 - val_acc: 0.8976\nEpoch 15/25\n7412/7412 [==============================] - 67s 9ms/sample - loss: 0.2632 - acc: 0.8952 - val_loss: 0.2385 - val_acc: 0.8973\nEpoch 16/25\n7412/7412 [==============================] - 67s 9ms/sample - loss: 0.2486 - acc: 0.9058 - val_loss: 0.2267 - val_acc: 0.9134\nEpoch 17/25\n7412/7412 [==============================] - 71s 10ms/sample - loss: 0.2406 - acc: 0.9054 - val_loss: 0.2269 - val_acc: 0.9093\nEpoch 18/25\n7412/7412 [==============================] - 70s 9ms/sample - loss: 0.2204 - acc: 0.9149 - val_loss: 0.2104 - val_acc: 0.9154\nEpoch 19/25\n7412/7412 [==============================] - 85s 11ms/sample - loss: 0.2218 - acc: 0.9143 - val_loss: 0.2622 - val_acc: 0.8992\nEpoch 20/25\n7412/7412 [==============================] - 75s 10ms/sample - loss: 0.2285 - acc: 0.9139 - val_loss: 0.2087 - val_acc: 0.9165\nEpoch 21/25\n7412/7412 [==============================] - 73s 10ms/sample - loss: 0.2152 - acc: 0.9146 - val_loss: 0.2079 - val_acc: 0.9132\nEpoch 22/25\n7412/7412 [==============================] - 75s 10ms/sample - loss: 0.2151 - acc: 0.9172 - val_loss: 0.2987 - val_acc: 0.8924\nEpoch 23/25\n7412/7412 [==============================] - 76s 10ms/sample - loss: 0.2244 - acc: 0.9120 - val_loss: 0.2114 - val_acc: 0.9184\nEpoch 24/25\n7412/7412 [==============================] - 76s 10ms/sample - loss: 0.2071 - acc: 0.9169 - val_loss: 0.2240 - val_acc: 0.9170\nEpoch 25/25\n7412/7412 [==============================] - 77s 10ms/sample - loss: 0.2016 - acc: 0.9230 - val_loss: 0.2348 - val_acc: 0.9088\n"}],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt \n","import seaborn as sns \n","import matplotlib.style as stl \n","stl.use('seaborn')\n","\n","from sklearn.model_selection import train_test_split\n","######################################################################\n","#First import the K.40mM \n","\n","traces = pd.read_csv(\"./data_in_csv/K.40mM/traces.csv\", index_col=0)\n","#some examples have na values get rid of\n","\n","traces = traces.dropna()\n","\n","tracesIndex = traces.index\n","#Randomize!!\n","\n","tracesIndex = tracesIndex[np.random.permutation(len(tracesIndex))]\n","\n","traces = traces.loc[tracesIndex,]\n","#This need to be a 3 dimensional numpy array\n","\n","traces = np.asarray(traces)\n","#Add the new Dimension\n","\n","traces = traces[...,np.newaxis]\n","#Load the Labels\n","\n","labels = pd.read_csv(\"./data_in_csv/K.40mM/labels.csv\", index_col=0)\n","#Load lables that match the traces above\n","\n","labels = labels.loc[tracesIndex,]\n","#Convert to Category\n","\n","labels = labels.iloc[:,0].astype('category')\n","#convert to np array\n","\n","labels = np.asarray(labels)\n","#Create Train and Validation Set\n","\n","val = int(np.ceil(traces.shape[0]*.33))\n","trainSize = traces.shape[0] - val \n","x_train  = traces[:trainSize,...]\n","y_train = labels[:trainSize]\n","x_test = traces[trainSize:,...]\n","\n","y_test = labels[trainSize:]\n","# Now DO what we need \n","\n","BATCH_SIZE = 256\n","BUFFER_SIZE = 10000\n","train = tf.data.Dataset.from_tensor_slices((traces, labels))\n","train = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","\n","test = test.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","#This Doesn't work for 3 dimension datasets\n","#X_train, X_test, y_train, y_test = train_test_split(traces, labels, test_size=0.33)\n","#Using this as a guide\n","#https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n","# Function to transform data set into 10 peices of \n","# Mean\n","# Standard Deviation\n","#To feed into LSTM we need 3 Dimensions\n","# 1 # of samples (11063)\n","# 2 # of features (2 mean and Standar Deviation)\n","# 3 # of timesteps\n","#This Helps to guide the model and loss\n","#https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","\n","model = Sequential([\n","    tf.keras.layers.LSTM(100, input_shape = traces.shape[-2:]),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss=\"binary_crossentropy\",\n","              metrics=['acc'])\n","\n","model.summary()\n","EVALUATION_INTERVAL = 200\n","EPOCHS = 10\n","\n","history = model.fit(train, epochs = EPOCHS, \n","                    steps_per_epoch=EVALUATION_INTERVAL,\n","                    validation_data = test,\n","                    validation_steps=50)\n","\n","history = model.fit(x_train, y_train, epochs=25, \n","                    validation_data=(x_test,y_test ))\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}